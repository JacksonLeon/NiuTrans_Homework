# NiuTrans_Homework

大作业：0-7数字异或

训练结果：

```
w: [array([[-1.15046194, -0.08497824, -0.24261121, -1.00917607,  1.22814205,
         0.38663843, -0.20980945,  1.60630145, -0.0827209 ,  0.73743835,
         0.7339584 ],
       [ 0.61665403,  1.18307964,  0.66804659,  0.75564422,  0.04522477,
         0.65598199, -1.68395741, -0.97965755,  1.15525243,  0.97482998,
        -1.67594811],
       [ 0.61507185,  1.36134613, -0.16347338, -0.33123814,  0.45269075,
        -0.58637423,  0.89633548, -0.91255282,  1.33733345, -1.1708771 ,
         2.04252428]]), array([[-1.28406547],
       [ 2.41184256],
       [-0.77863531],
       [-0.03615916],
       [ 1.22931493],
       [-0.6929963 ],
       [ 1.69252959],
       [ 1.68609875],
       [ 2.15486539],
       [-1.14821357],
       [-3.43057752]])]
[['000', '000'], ['000', '001'], ['000', '010'], ['000', '011'], ['000', '100'], ['000', '101'], ['000', '110'], ['000', '111'], ['001', '000'], ['001', '001'], ['001', '010'], ['001', '011'], ['001', '100'], ['001', '101'], ['001', '110'], ['001', '111'], ['010', '000'], ['010', '001'], ['010', '010'], ['010', '011'], ['010', '100'], ['010', '101'], ['010', '110'], ['010', '111'], ['011', '000'], ['011', '001'], ['011', '010'], ['011', '011'], ['011', '100'], ['011', '101'], ['011', '110'], ['011', '111'], ['100', '000'], ['100', '001'], ['100', '010'], ['100', '011'], ['100', '100'], ['100', '101'], ['100', '110'], ['100', '111'], ['101', '000'], ['101', '001'], ['101', '010'], ['101', '011'], ['101', '100'], ['101', '101'], ['101', '110'], ['101', '111'], ['110', '000'], ['110', '001'], ['110', '010'], ['110', '011'], ['110', '100'], ['110', '101'], ['110', '110'], ['110', '111'], ['111', '000'], ['111', '001'], ['111', '010'], ['111', '011'], ['111', '100'], ['111', '101'], ['111', '110'], ['111', '111']]
[-0.00040922]
[0.99959109]
[1.99959139]
[2.9995917]
[3.99959201]
[4.99959231]
[5.99959262]
[6.99959293]
[0.99959256]
[-0.00039904]
[2.99959317]
[1.99960157]
[4.99959378]
[3.99960219]
[6.9995944]
[5.9996028]
[1.99959434]
[2.99959464]
[-0.00038886]
[0.99961145]
[5.99959556]
[6.99959587]
[3.99961237]
[4.99961267]
[2.99959611]
[1.99960452]
[0.99961292]
[-0.00037868]
[6.99959734]
[5.99960574]
[4.99961415]
[3.99962255]
[3.99959789]
[4.9995982]
[5.9995985]
[6.99959881]
[-0.0003685]
[0.99963181]
[1.99963212]
[2.99963242]
[4.99959967]
[3.99960807]
[6.99960028]
[5.99960868]
[0.99963328]
[-0.00035832]
[2.99963389]
[1.9996423]
[5.99960144]
[6.99960175]
[3.99961825]
[4.99961856]
[1.99963506]
[2.99963536]
[-0.00034813]
[0.99965217]
[6.99960322]
[5.99961162]
[4.99962003]
[3.99962843]
[2.99963684]
[1.99964524]
[0.99965364]
[-0.00033795]
loss: 1.5071888558982218e-07
0 -0.0004092189603764962 -0.0004092189603764962
1 0.9995910874777432 -0.0004089125222568324
2 1.999591393915863 -0.00040860608413706423
3 2.9995917003539825 -0.0004082996460175181
4 3.9995920067921023 -0.00040799320789774995
5 4.999592313230222 -0.0004076867697779818
6 5.999592619668341 -0.0004073803316586577
7 6.999592926106461 -0.00040707389353933365
1 0.9995925581304215 -0.0004074418695785287
0 -0.0003990382082069745 -0.0003990382082069745
3 2.999593171006661 -0.0004068289933392144
2 1.9996015746680325 -0.0003984253319675446
5 4.9995937838829 -0.0004062161171001222
4 3.9996021875442715 -0.00039781245572845236
7 6.999594396759139 -0.00040560324086058586
6 5.999602800420511 -0.00039719957948936013
2 1.9995943352212195 -0.0004056647787804568
3 2.999594641659339 -0.0004053583406609107
0 -0.0003888574560374528 -0.0003888574560374528
1 0.9996114489820822 -0.0003885510179177931
6 5.999595560973698 -0.0004044390263020503
7 6.999595867411817 -0.00040413258818272624
4 3.9996123682964413 -0.0003876317035587107
5 4.999612674734561 -0.0003873252654393866
3 2.9995961123120174 -0.000403887687982607
2 1.999604515973389 -0.0003954840266109372
1 0.9996129196347605 -0.0003870803652394894
0 -0.0003786767038679311 -0.0003786767038679311
7 6.999597338064496 -0.00040266193550397844
6 5.999605741725867 -0.0003942582741327527
5 4.999614145387239 -0.0003858546127606388
4 3.9996225490486106 -0.0003774509513894131
4 3.9995978894028155 -0.0004021105971845351
5 4.999598195840935 -0.00040180415906476696
6 5.999598502279055 -0.0004014977209454429
7 6.999598808717174 -0.0004011912828261188
0 -0.0003684959516984094 -0.0003684959516984094
1 0.9996318104864212 -0.00036818951357875385
2 1.999632116924541 -0.0003678830754589857
3 2.9996324233626606 -0.00036757663733943957
5 4.999599666493613 -0.00040033350638690735
4 3.9996080701549848 -0.00039192984501523753
7 6.999600279369853 -0.000399720630147371
6 5.999608683031224 -0.0003913169687761453
1 0.9996332811390995 -0.00036671886090045014
0 -0.0003583151995288877 -0.0003583151995288877
3 2.999633894015339 -0.00036610598466113586
2 1.9996422976767105 -0.00035770232328946605
6 5.999601443584411 -0.0003985564155888355
7 6.9996017500225305 -0.0003982499774695114
4 3.9996182509071545 -0.00038174909284549585
5 4.999618557345274 -0.0003814426547261718
2 1.9996350582298976 -0.00036494177010237827
3 2.999635364668017 -0.00036463533198283216
0 -0.000348134447359366 -0.000348134447359366
1 0.9996521719907603 -0.0003478280092397146
7 6.999603220675209 -0.0003967793247907636
6 5.9996116243365805 -0.0003883756634195379
5 4.999620027997953 -0.000379972002047424
4 3.999628431659324 -0.00037156834067619826
3 2.9996368353206955 -0.00036316467930452845
2 1.9996452389820671 -0.00035476101793285864
1 0.9996536426434386 -0.00034635735656141087
0 -0.0003379536951898443 -0.0003379536951898443
accuracy: 64 / 64 = 1.0
```

课堂练习：[基于NiuTensor的FNNLM](https://gitee.com/JacksonLeon/NiuTrans-Homework.git)

通过简单调参，能够将ppl从231.69降到201.54

训练命令：`bin/NiuTensor.GPU -fnnlm -dev 2 -lrate 0.006 -wbatch 256 -minmax 0.1 -nepoch 5 -n 5 -hdepth 1 -hsize 128 -esize 100 -train data/wsj.train -test data/wsj.test -output work/wsj-1.prob -vsize 10000 -model work/wsj-1.model -autodiff`

1.使用NiuTensor实现10以内数字的异或

2.实现sequence2sequence模型

> FNNLM训练(ppl=201.54)过程如下：
```
args:
 -dev=3
 -lrate=0.006000
 -wbatch=256
 -minmax=0.100000
 -nepoch=5
 -n=5
 -hdepth=1
 -hsize=128
 -esize=100
 -train=data/wsj.train
 -test=data/wsj.test
 -output=work/wsj.prob
 -vsize=10000
 -model=work/wsj.model
 -autodiff=true
[INFO] elapsed=29.9s, step=100, epoch=1, ngram=25600, ppl=1407.175
[INFO] elapsed=65.6s, step=200, epoch=1, ngram=51200, ppl=1026.999
[INFO] elapsed=101.3s, step=300, epoch=1, ngram=76800, ppl=855.181
[INFO] elapsed=139.7s, step=400, epoch=1, ngram=102400, ppl=751.295
[INFO] elapsed=174.6s, step=500, epoch=1, ngram=128000, ppl=688.269
[INFO] elapsed=201.6s, step=600, epoch=1, ngram=153600, ppl=635.385
[INFO] elapsed=237.5s, step=700, epoch=1, ngram=179200, ppl=594.812
[INFO] elapsed=272.3s, step=800, epoch=1, ngram=204800, ppl=569.784
[INFO] elapsed=311.0s, step=900, epoch=1, ngram=230400, ppl=541.213
[INFO] ppl=297.65
[INFO] test finished (took 44.3s, sentence=1359 and ngram=30192)
[INFO] elapsed=391.2s, step=1000, epoch=2, ngram=255992, ppl=344.523
[INFO] elapsed=430.7s, step=1100, epoch=2, ngram=281592, ppl=331.115
[INFO] elapsed=457.3s, step=1200, epoch=2, ngram=307192, ppl=319.903
[INFO] elapsed=485.4s, step=1300, epoch=2, ngram=332792, ppl=310.391
[INFO] elapsed=516.9s, step=1400, epoch=2, ngram=358392, ppl=307.981
[INFO] elapsed=545.3s, step=1500, epoch=2, ngram=383992, ppl=298.710
[INFO] elapsed=571.3s, step=1600, epoch=2, ngram=409592, ppl=293.196
[INFO] elapsed=599.2s, step=1700, epoch=2, ngram=435192, ppl=291.659
[INFO] elapsed=623.5s, step=1800, epoch=2, ngram=460792, ppl=286.164
[INFO] ppl=238.67
[INFO] test finished (took 34.3s, sentence=1359 and ngram=30192)
[INFO] elapsed=684.4s, step=1900, epoch=3, ngram=486384, ppl=251.827
[INFO] elapsed=709.2s, step=2000, epoch=3, ngram=511984, ppl=235.794
[INFO] elapsed=736.1s, step=2100, epoch=3, ngram=537584, ppl=230.734
[INFO] elapsed=746.7s, step=2200, epoch=3, ngram=563184, ppl=222.162
[INFO] elapsed=747.9s, step=2300, epoch=3, ngram=588784, ppl=223.054
[INFO] elapsed=749.1s, step=2400, epoch=3, ngram=614384, ppl=216.743
[INFO] elapsed=750.3s, step=2500, epoch=3, ngram=639984, ppl=214.492
[INFO] elapsed=751.5s, step=2600, epoch=3, ngram=665584, ppl=214.493
[INFO] elapsed=752.7s, step=2700, epoch=3, ngram=691184, ppl=211.622
[INFO] ppl=216.26
[INFO] test finished (took 18.7s, sentence=1359 and ngram=30192)
[INFO] elapsed=790.6s, step=2800, epoch=4, ngram=716776, ppl=197.779
[INFO] elapsed=817.9s, step=2900, epoch=4, ngram=742376, ppl=184.935
[INFO] elapsed=846.2s, step=3000, epoch=4, ngram=767976, ppl=182.793
[INFO] elapsed=872.3s, step=3100, epoch=4, ngram=793576, ppl=175.429
[INFO] elapsed=901.7s, step=3200, epoch=4, ngram=819176, ppl=176.372
[INFO] elapsed=926.4s, step=3300, epoch=4, ngram=844776, ppl=171.712
[INFO] elapsed=953.6s, step=3400, epoch=4, ngram=870376, ppl=170.018
[INFO] elapsed=983.0s, step=3500, epoch=4, ngram=895976, ppl=170.164
[INFO] elapsed=1009.8s, step=3600, epoch=4, ngram=921576, ppl=168.001
[INFO] ppl=205.10
[INFO] test finished (took 36.1s, sentence=1359 and ngram=30192)
[INFO] elapsed=1068.7s, step=3700, epoch=5, ngram=947168, ppl=163.334
[INFO] elapsed=1091.3s, step=3800, epoch=5, ngram=972768, ppl=150.263
[INFO] elapsed=1117.3s, step=3900, epoch=5, ngram=998368, ppl=150.108
[INFO] elapsed=1147.4s, step=4000, epoch=5, ngram=1023968, ppl=142.465
[INFO] elapsed=1168.6s, step=4100, epoch=5, ngram=1049568, ppl=143.813
[INFO] elapsed=1196.5s, step=4200, epoch=5, ngram=1075168, ppl=141.933
[INFO] elapsed=1227.2s, step=4300, epoch=5, ngram=1100768, ppl=139.638
[INFO] elapsed=1251.5s, step=4400, epoch=5, ngram=1126368, ppl=139.994
[INFO] elapsed=1276.8s, step=4500, epoch=5, ngram=1151968, ppl=138.458
[INFO] ppl=201.54
[INFO] test finished (took 34.3s, sentence=1359 and ngram=30192)
[INFO] elapsed=1323.7s, step=4550, epoch=5, ngram=1164760, ppl=138.094
[INFO] training finished (took 1323.7s, step=4550 and epoch=5)
[INFO] model saved
[INFO] model loaded
[INFO] ppl=201.54
[INFO] test finished (took 37.5s, sentence=1359 and ngram=30192)
```
